{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "%matplotlib inline\n",
    "import math\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenaufbereitung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der Daten\n",
    "import os\n",
    "\n",
    "data_path='/domino/datasets/local/TestData/iboxx_eur/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Komponenten als monatsweises Dictionary von DataFrames \n",
    "\n",
    "comp_list=os.listdir(data_path+'Components/')\n",
    "\n",
    "comp={}\n",
    "\n",
    "for file in comp_list:\n",
    "    comp[file[-10:-4]]=pd.read_csv(data_path+'Components/'+file,encoding='latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indizes als ein GesamtDataframe auf täglicher Basis\n",
    "\n",
    "indices_list=os.listdir(data_path+'Indices')\n",
    "\n",
    "indices={}\n",
    "\n",
    "for file in indices_list:\n",
    "    indices[file[-12:-4]]=pd.read_csv(data_path+'Indices/'+file,encoding='latin_1')\n",
    "\n",
    "i=0\n",
    "\n",
    "for days in indices:\n",
    "    if i==0:\n",
    "        indices_df=pd.DataFrame(indices[days])\n",
    "    else:\n",
    "        indices_df=indices_df.append(indices[days],ignore_index=True)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Underlyings als ein GesamtDataframe auf täglicher Basis\n",
    "\n",
    "underlyings_list=os.listdir(data_path+'Underlyings')\n",
    "\n",
    "underlyings={}\n",
    "\n",
    "for file in underlyings_list:\n",
    "    underlyings[file[-12:-4]]=pd.read_csv(data_path+'Underlyings/'+file,encoding='latin_1')\n",
    "\n",
    "## Underlyings als ein GesamtDataframe auf täglicher Basis\n",
    "\n",
    "underlyings_list=os.listdir(data_path+'Underlyings')\n",
    "\n",
    "underlyings={}\n",
    "\n",
    "for file in underlyings_list:\n",
    "    underlyings[file[-12:-4]]=pd.read_csv(data_path+'Underlyings/'+file,encoding='latin_1')\n",
    "    \n",
    "underlyings_df=pd.DataFrame()\n",
    "\n",
    "for days in underlyings:\n",
    "    underlyings_df=underlyings_df.append(underlyings[days][['Date','ISIN','Index Price','Daily Return']],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLAIT - Specialized LAIT with upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_HETE(x,M=0.1):\n",
    "    if abs(x)<=M:\n",
    "        return 1\n",
    "    else:\n",
    "        return M/abs(x)\n",
    "\n",
    "def b_HETE(x,M=0.1):\n",
    "    if abs(x)<=M:\n",
    "        return 0\n",
    "    else:\n",
    "        return M(abs(x)-M)\n",
    "\n",
    "def b_HDR(x,M=0.1):\n",
    "    if x<=M:\n",
    "        return 0\n",
    "    else:\n",
    "        return M(abs(x)-M)\n",
    "    \n",
    "def a_HDR(x,M=0.1):\n",
    "    if x<0:\n",
    "        return M/(M-2*x)\n",
    "    elif x<=M:\n",
    "        return 1\n",
    "    else:\n",
    "        return M/abs(x)\n",
    "\n",
    "def c(x):\n",
    "    if x<0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def d (gamma,p,w):\n",
    "    return 1/math.log(1+gamma/p)/(p+w)\n",
    "    \n",
    "def A(q,u=1,maxiter=1000):\n",
    "    print('Start binary search')\n",
    "    \n",
    "    # indirect sort of q\n",
    "    q_sortindex=q.argsort()\n",
    "    \n",
    "    i=1\n",
    "    a=1\n",
    "    e=len(q)\n",
    "    K=(a+e)//2\n",
    "    mue=-(q[q_sortindex[range(K-1)]].sum()+2)/(K)\n",
    "    A=(mue+q)<0\n",
    "    w=-(mue*np.ones(len(q))+q)/2\n",
    "    #print(A.sum(),'==',K,'-- a=',a,' und e=',e)\n",
    "        \n",
    "    while (A.sum()!=K) & (i<=maxiter):\n",
    "        i=i+1\n",
    "        if A.sum()>K:\n",
    "            a=K+1\n",
    "            K=(a+e)//2\n",
    "        else:\n",
    "            e=K-1\n",
    "            K=(a+e)//2\n",
    "        mue=-(q[q_sortindex[range(K-1)]].sum()+2)/(K)\n",
    "        A=(mue+q)<0\n",
    "        #print(A.sum(),'==',K,'-- a=',a,' und e=',e)\n",
    "        if A.sum()==K or e<a or i>maxiter:\n",
    "            w=-(mue*np.ones(len(q))+q)/2\n",
    "            break\n",
    "        elif A.sum()==0:\n",
    "             raise ValueError('Only zero weights')\n",
    "        \n",
    "    print('Found optimal K without upper bound. ',(w>u).sum(),' components above upper bound')\n",
    "        \n",
    "    if (u<1) & (u>0) & ((w>u).sum()>0):\n",
    "        \n",
    "        print('Start combined binary search')\n",
    "        \n",
    "        if 1/u>len(q):\n",
    "            raise ValueError('upper bound too low')\n",
    "            \n",
    "        c=q+2*u\n",
    "        \n",
    "        for k in np.arange(K,len(q)+1):\n",
    "            #print('K_opt == ',k)\n",
    "            i=1\n",
    "            a=1\n",
    "            e=k\n",
    "            K1=(a+e)//2\n",
    "            K2=k-K1            \n",
    "        \n",
    "            mue=-(q[q_sortindex[K1:k-1]].sum()-2*K1*u+2)/K2\n",
    "            B1=(mue+c)<=0\n",
    "            B2=(0<mue+c) & (mue+c<2*u)\n",
    "            \n",
    "            #print(B1.sum(),'==',K1,' -- ',B2.sum(),'==',K2,'-- a=',a,' und e=',e)\n",
    "\n",
    "            while (a<=e):\n",
    "                \n",
    "                i=i+1\n",
    "                \n",
    "                if B1.sum()>K1:\n",
    "                    a=K1+1\n",
    "                    K1=(a+e)//2\n",
    "                    K2=k-K1 \n",
    "                else:\n",
    "                    e=K1-1\n",
    "                    K1=(a+e)//2\n",
    "                    K2=k-K1 \n",
    "                \n",
    "                mue=-(q[q_sortindex[K1:k-1]].sum()-2*K1*u+2)/K2\n",
    "                B1=(mue+c)<=0\n",
    "                B2=(0<mue+c) & (mue+c<2*u)\n",
    "                \n",
    "                #print(B1.sum(),'==',K1,' -- ',B2.sum(),'==',K2,'-- a=',a,' und e=',e)\n",
    "\n",
    "                if (B1.sum()==K1) & (B2.sum()==K2):\n",
    "                    w=np.minimum(-(mue*np.ones(len(q))+q)/2,u*np.ones(len(q)))\n",
    "                    break\n",
    "                #elif (B1.sum()==0) | (B2.sum()==0):\n",
    "                    #raise ValueError('Only zero weights')\n",
    "            \n",
    "            if (B1.sum()==K1) & (B2.sum()==K2):\n",
    "                break\n",
    "        if ((B1.sum()!=K1) or (B2.sum()!=K2)):\n",
    "            w[q_sortindex[range(math.ceil(1/u))]]=u\n",
    "            w=w/w.sum()\n",
    "    \n",
    "    return np.maximum(w,0)\n",
    "\n",
    "av_HETE=np.vectorize(a_HETE)\n",
    "av_HDR=np.vectorize(a_HDR)\n",
    "bv_HETE=np.vectorize(b_HETE)\n",
    "bv_HDR=np.vectorize(b_HDR)\n",
    "cv=np.vectorize(c)\n",
    "dv=np.vectorize(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLAIT(X,r,lamb=1e-7,u=1,maxiter=1000,measure='ETE',eps=1e-9,w0=None,M=None,gamma=0.2,p=1e-6,thres=1e-3,ret=False):\n",
    "    \n",
    "    ################# error control ########################\n",
    "    IDs=X.keys()\n",
    "    X=np.array(X)\n",
    "    r=np.array(r)\n",
    "    T,n=X.shape # T is days, n number of constituents\n",
    "    if n==1:\n",
    "        raise ValueError('Data is univariate!')\n",
    "    if pd.isna(X).sum()>0|pd.isna(r).sum()>0|pd.isna(lamb)|pd.isna(u):\n",
    "        raise ValueError('Some arguments contain NaNs')\n",
    "    if (measure in ['HETE','HDR'])&(pd.isnull(M)|(M<=0)):\n",
    "        raise ValueError('The huber parameter should be positive')\n",
    "    if (u>1)|(u<=0):\n",
    "        raise ValueError('upper bound not in range (0,1]')\n",
    "    if measure not in ['ETE','HETE','DR','HDR']:\n",
    "        raise ValueError(measure,' is no valid measure!')\n",
    "    ########################################################\n",
    "    \n",
    "    if w0 is None:\n",
    "        w=np.ones(n) \n",
    "        w=w/w.sum() # equal weights for every component\n",
    "    else:\n",
    "        if np.isnan(w0).any():\n",
    "            raise ValueError('NaNs in start vector')\n",
    "        else:\n",
    "            w=w0\n",
    "    \n",
    "    k=0\n",
    "    conv=eps\n",
    "    \n",
    "    if measure in ['ETE','DR']: \n",
    "        L1=(X.T@X)/T\n",
    "        lamb_max=np.linalg.eigvalsh(L1).max()\n",
    "    \n",
    "    elif measure in ['HETE','HDR']:\n",
    "        av=av_HETE(r-X@w)\n",
    "        aDiag=np.eye(T)\n",
    "        np.fill_diagonal(aDiag,av)\n",
    "        L2=(X.T@aDiag@X)/T\n",
    "        lamb_max=np.linalg.eigvalsh(L2).max()\n",
    "    \n",
    "    while (conv>=eps) & (k<=maxiter):\n",
    "        if measure=='ETE':\n",
    "            q=(2*(L1-lamb_max*np.eye(n))@w+lamb*dv(gamma,p,w)-2/T*X.T@r)/lamb_max\n",
    "        elif measure=='DR':\n",
    "            y=-np.maximum(X@w-r,0)\n",
    "            q=(2*(L1-lamb_max*np.eye(n))@w+lamb*dv(gamma,p,w)-2/T*X.T@(y-r))/lamb_max\n",
    "        elif measure=='HETE':\n",
    "            av=av_HETE(r-X@w)\n",
    "            aDiag=np.eye(T)\n",
    "            np.fill_diagonal(aDiag,av)\n",
    "            q=(2*(L2-lamb_max*np.eye(n))@w+lamb*dv(gamma,p,w)-2/T*X.T@aDiag@r)/lamb_max\n",
    "        else:\n",
    "            av=av_HDR(r-X@w)\n",
    "            aDiag=np.eye(T)\n",
    "            np.fill_diagonal(aDiag,av)\n",
    "            L3=X.T@aDiag@X/T\n",
    "            lamb_max=np.linalg.eigvalsh(L3).max()\n",
    "            q=(2*(L3-lamb_max*np.eye(n))@w+lamb*dv(gamma,p,w)-2/T*X.T@aDiag@(cv(r-X@w-r)))/lamb_max\n",
    "        w0=w\n",
    "        w=A(q,u,maxiter)\n",
    "        #conv=norm(w0-w)\n",
    "        k=k+1\n",
    "        \n",
    "        #Needs python 3.10 \n",
    "        #match measure:\n",
    "            #case 'ETE':\n",
    "            #    print('Iteration: ',k,'--> Zielfunktion: ',ETE(X,r,w),' and w: ',w)\n",
    "            #case 'DR':\n",
    "            #    print('Iteration: ',k,'--> Zielfunktion: ',DR(X,r,w),' and w: ',w)\n",
    "            #case 'HETE':\n",
    "            #    print('Iteration: ',k,'--> Zielfunktion: ',HETE(X,r,w,M),' and w: ',w)\n",
    "            #case 'HDR':\n",
    "            #    print('Iteration: ',k,'--> Zielfunktion: ',HDR(X,r,w,M),' and w: ',w)\n",
    "        \n",
    "        if measure=='ETE':\n",
    "            print('Iteration: ',k,'Komponenten: ',(w>0).sum(),'--> Zielfunktion: ',ETE(X,r,w)+dv(gamma,p,w).T@w, \\\n",
    "                  'Maß: ',ETE(X,r,w),' and w: ',w)\n",
    "            conv=abs(ETE(X,r,w0)-ETE(X,r,w))+abs(dv(gamma,p,w0).T@w0-dv(gamma,p,w).T@w)\n",
    "        elif measure=='DR':\n",
    "            print('Iteration: ',k,'Komponenten: ',(w>0).sum(),'--> Zielfunktion: ',DR(X,r,w)+dv(gamma,p,w).T@w, \\\n",
    "                  'Maß: ',DR(X,r,w),' and w: ',w)\n",
    "            conv=abs(DR(X,r,w0)-DR(X,r,w))+abs(dv(gamma,p,w0).T@w0-dv(gamma,p,w).T@w)\n",
    "        elif measure=='HETE':\n",
    "            print('Iteration: ',k,'Komponenten: ',(w>0).sum(),'--> Zielfunktion: ',HETE(X,r,w,M)+dv(gamma,p,w).T@w, \\\n",
    "                  'Maß: ',HETE(X,r,w,M),' and w: ',w)\n",
    "            conv=abs(HETE(X,r,w0)-HETE(X,r,w))+abs(dv(gamma,p,w0).T@w0-dv(gamma,p,w).T@w)\n",
    "        else:\n",
    "            print('Iteration: ',k,'Komponenten: ',(w>0).sum(),'--> Zielfunktion: ',HDR(X,r,w,M)+dv(gamma,p,w).T@w,\\\n",
    "                  'Maß: ',HDR(X,r,w,M),' and w: ',w)\n",
    "            conv=abs(HDR(X,r,w0)-HDR(X,r,w))+abs(dv(gamma,p,w0).T@w0-dv(gamma,p,w).T@w)\n",
    "            \n",
    "    if w.max()>thres:\n",
    "        w=np.where(w<thres,0,w)\n",
    "    w=np.nan_to_num(w)\n",
    "    w=w/w.sum()\n",
    "    \n",
    "    W=pd.DataFrame({'ISIN':IDs,'Weight':w})\n",
    "                \n",
    "    return W\n",
    "\n",
    "def ETE(X,r,w):\n",
    "    T,n=X.shape\n",
    "    return norm(X@w-r)**2/T\n",
    "\n",
    "def DR(X,r,w):\n",
    "    T,n=X.shape\n",
    "    return norm(np.maximum(r-X@w,0))**2/T\n",
    "\n",
    "def phi(x,M):\n",
    "    if x<=abs(M):\n",
    "        return x**2\n",
    "    else:\n",
    "        return M*(2*abs(x)-M)\n",
    "    \n",
    "phiv=np.vectorize(phi)\n",
    "\n",
    "def HETE(X,r,w,M):\n",
    "    T,n=X.shape\n",
    "    return np.ones(T).T@phiv(X@w-r,M)/T\n",
    "\n",
    "def HDR(X,r,w,M):\n",
    "    T,n=X.shape\n",
    "    return np.ones(T).T@phiv(np.maximum(r-X@w,0),M)/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_replicated(w,Index,Comp,Ret=True,Start=100):\n",
    "    plt.figure(i,figsize=(15,5))\n",
    "\n",
    "    \n",
    "    return_reb=Comp@w\n",
    "    return_org=Index\n",
    "    \n",
    "    r=range(len(return_reb))\n",
    "    \n",
    "    if Ret==False:\n",
    "        price_reb=return_reb\n",
    "        price_org=return_org\n",
    "        return_reb=np.zeros(len(price_reb))\n",
    "        return_org=np.zeros(len(price_reb))\n",
    "        for j in r:\n",
    "            if j==0:\n",
    "                return_reb[j]=Start\n",
    "                return_org[j]=Start\n",
    "            else:\n",
    "                return_reb[j]=return_reb[j-1]*(1+np.log(price_reb[j]/price_reb[j-1]))\n",
    "                return_org[j]=return_org[j-1]*(1+np.log(price_org[j]/price_org[j-1]))\n",
    "    r=np.array(Index.index)\n",
    "    plt.plot(r,return_reb, label='rebuild')\n",
    "    plt.plot(r,return_org, label='original')\n",
    "            \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class portfolio (object):\n",
    "    def __init__(self,weight=None,underlying=None,index=None,components=None):\n",
    "            self.weight=weight\n",
    "            self.underlying=underlying\n",
    "            self.index=index\n",
    "            self.components=components\n",
    "            \n",
    "    def plt_replicated(self,Start=100):\n",
    "        plt.figure(i,figsize=(15,5))\n",
    "        \n",
    "        data=pd.merge_asof(self.underlying,self.weight,on='Date',by='ISIN',direction='backward',allow_exact_matches=False) \\\n",
    "        .dropna()\n",
    "        data['WeightReturn']=data['Weight']*data['Daily Return']\n",
    "        data=data.groupby('Date').sum()\n",
    "        data=pd.merge(data,self.index,on='Date')\n",
    "        \n",
    "    \n",
    "        return_reb=np.array(data['WeightReturn'])\n",
    "        return_org=np.array(data['Daily Return_y'])\n",
    "    \n",
    "        r=range(len(return_reb))\n",
    "    \n",
    "        for j in range(len(return_reb)):\n",
    "            if j==0:\n",
    "                return_reb[j]=Start\n",
    "                return_org[j]=Start\n",
    "            else:\n",
    "                return_reb[j]=return_reb[j-1]*(1+return_reb[j])\n",
    "                return_org[j]=return_org[j-1]*(1+return_org[j])\n",
    "        r=data.index\n",
    "        plt.plot(r,return_reb, label='rebuild')\n",
    "        plt.plot(r,return_org, label='original')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def number_components(self):\n",
    "        return self.weight[self.weight['Weight']>0][['Date','ISIN']].groupby('Date').count()\n",
    "    \n",
    "    def compare(self,on,date=None):\n",
    "        if pd.isna(date):\n",
    "            date=self.weight['Date'].max()\n",
    "        data=pd.merge(self.components[date.strftime('%Y%m')],self.weight[self.weight['Date']==date],on='ISIN',how='left').fillna(0)\n",
    "        data['Index Weight']=data['Index Weight']/data['Index Weight'].sum()\n",
    "        if self.components[date.strftime('%Y%m')][on].dtype=='float64':\n",
    "            data[on]=round(data[on],0)\n",
    "            print('Rebuild ',on,': ',np.average(data[on], weights=data['Weight']))\n",
    "            print('Index ',on,': ',np.average(data[on], weights=data['Index Weight']))\n",
    "        data.groupby(on).sum()[['Weight','Index Weight']].plot(kind='bar',figsize=(25,5))\n",
    "    \n",
    "    def compare_list(self):\n",
    "        return list(self.components[list(self.components.keys())[0]].keys())\n",
    "    \n",
    "    def ETE(self,ret=True,Start=1):\n",
    "        data=pd.merge_asof(self.underlying,self.weight,on='Date',by='ISIN',direction='backward',allow_exact_matches=False) \\\n",
    "        .dropna()\n",
    "        data['WeightReturn']=data['Weight']*data['Daily Return']\n",
    "        data=data.groupby('Date').sum()\n",
    "        data=pd.merge(data,self.index,on='Date')\n",
    "        return_reb=np.array(data['WeightReturn'])\n",
    "        return_org=np.array(data['Daily Return_y'])\n",
    "        \n",
    "        # Vergleich auf Preisbasis\n",
    "        if ret==False:\n",
    "            for j in range(len(return_reb)):\n",
    "                if j==0:\n",
    "                    return_reb[j]=Start\n",
    "                    return_org[j]=Start\n",
    "                else:\n",
    "                    return_reb[j]=return_reb[j-1]*(1+return_reb[j])\n",
    "                    return_org[j]=return_org[j-1]*(1+return_org[j])\n",
    "                \n",
    "        return norm(return_reb-return_org)**2/len(return_reb)\n",
    "    \n",
    "    def DR(self,ret=True,Start=1):\n",
    "        data=pd.merge_asof(self.underlying,self.weight,on='Date',by='ISIN',direction='backward',allow_exact_matches=False) \\\n",
    "        .dropna()\n",
    "        data['WeightReturn']=data['Weight']*data['Daily Return']\n",
    "        data=data.groupby('Date').sum()\n",
    "        data=pd.merge(data,self.index,on='Date')\n",
    "        return_reb=np.array(data['WeightReturn'])\n",
    "        return_org=np.array(data['Daily Return_y'])\n",
    "        \n",
    "        # Vergleich auf Preisbasis\n",
    "        if ret==False:\n",
    "            for j in range(len(return_reb)):\n",
    "                if j==0:\n",
    "                    return_reb[j]=Start\n",
    "                    return_org[j]=Start\n",
    "                else:\n",
    "                    return_reb[j]=return_reb[j-1]*(1+return_reb[j])\n",
    "                    return_org[j]=return_org[j-1]*(1+return_org[j])\n",
    "                \n",
    "        return norm(np.maximum(return_org-return_reb,0))**2/len(return_org)\n",
    "    \n",
    "    def trading_cost(self,base=100,c=5e-4):\n",
    "        data=self.weight.pivot(columns='Date',values='Weight',index='ISIN').fillna(0)\n",
    "        \n",
    "        for (i,date) in enumerate(data.columns):\n",
    "            if i==0:\n",
    "                cost=0\n",
    "            cost=cost+c*norm(data.iloc[:,i]-data.iloc[:,i-1])            \n",
    "                \n",
    "        return cost*base\n",
    "    \n",
    "    def bid_ask_trading(self, volume=1, c_fix=5e-4,prc_factor=100):\n",
    "        data=self.weight.pivot(columns='Date',values='Weight',index='ISIN').fillna(0)\n",
    "        \n",
    "        for (i,date) in enumerate(data.columns):\n",
    "            comp_price=pd.merge(self.components[date.strftime('%Y%m')][['ISIN','Bid Price', 'Ask Price', 'Index Price']] \\\n",
    "                                ,data[date],on='ISIN')\n",
    "            comp_price['Ask Nom']=comp_price.iloc[:,4]*volume/comp_price['Ask Price']*prc_factor\n",
    "            comp_price['Bid Nom']=comp_price.iloc[:,4]*volume/comp_price['Bid Price']*prc_factor\n",
    "            comp_price['Index Nom']=comp_price.iloc[:,4]*volume/comp_price['Index Price']*prc_factor\n",
    "            \n",
    "            if i==0:\n",
    "                Nom=pd.DataFrame(comp_price['Ask Nom']).rename_axis(date)\n",
    "                Prc=pd.DataFrame(comp_price['Ask Price']).rename_axis(date)\n",
    "                value=volume-(Nom*Prc/prc_factor).sum()-(Nom*c_fix).sum()\n",
    "                value_series={date:value}\n",
    "            else:\n",
    "                Nom[date]=np.where(Nom.iloc[:,i-1]-comp_price['Index Nom']<0,comp_price['Ask Nom'],comp_price['Bid Nom'])\n",
    "                Prc[date]=np.where(Nom.iloc[:,i-1]-comp_price['Index Nom']<0,comp_price['Ask Price'],comp_price['Bid Price'])               \n",
    "                value=value+((Nom.iloc[:,i-1]-Nom.iloc[:,i])*Prc[date]/prc_factor).sum() \\\n",
    "                            -(abs(Nom.iloc[:,i-1]-Nom.iloc[:,i])*c_fix).sum()\n",
    "                value_series={date:value}\n",
    "        \n",
    "            return value,value_series,Nom,Prc\n",
    "            \n",
    "    def normalize_weight(self,nominal=None,min_piece=None,weight_step=None,inplace=False):\n",
    "        if not pd.isna(nominal) or not pd.isna(min_piece):\n",
    "            weight_step=min_piece/nominal\n",
    "        elif pd.isna(weight_step):\n",
    "            raise ValueError('No argument given')\n",
    "            \n",
    "        data=self.weight.pivot(columns='Date',values='Weight',index='ISIN').fillna(0)\n",
    "        \n",
    "        for (i,date) in enumerate(data.columns):\n",
    "            if i==0:\n",
    "                data[date]=(round(data[date]/weight_step,0))*weight_step\n",
    "            else:\n",
    "                weight_new=(round(data[date]/weight_step))*weight_step\n",
    "                data.iloc[:,i]=np.where(abs(data.iloc[:,i]-data.iloc[:,i-1])>weight_step,data.iloc[:,i],data.iloc[:,i-1])\n",
    "                #data.iloc[:,i-1]+((data.iloc[:,i]-data.iloc[:,i-1])//weight_step)*weight_step\n",
    "        \n",
    "        data=data.reset_index().melt(value_vars=data.columns,id_vars='ISIN',value_name='Weight')\\\n",
    "            .dropna().reset_index(drop=True)\n",
    "        if inplace:\n",
    "            self.weight=data[['ISIN','Weight','Date']]\n",
    "        else:\n",
    "            return data[['ISIN','Weight','Date']]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiPeriod_SLAIT(X,r,Comp,IndexISIN='DE0009682716',Startdate=None,Enddate=None,m_rebal_freq=1,MonthRew=1, \\\n",
    "                      lamb=1e-7,u=1,maxiter=1000,measure='ETE' \\\n",
    "                      ,eps=1e-9,w0=None,M=0.1,gamma=0.2,p=1e-6,thres=1e-3,ret=False):\n",
    "\n",
    "    # Datenvorbereitung\n",
    "    r=r.sort_values('Date',ignore_index=True)\n",
    "    X=X.sort_values(['Date','ISIN'],ignore_index=True)\n",
    "\n",
    "    r=r.set_index(pd.to_datetime(r.Date)).drop('Date',axis=1)\n",
    "    X=X.set_index(pd.to_datetime(X.Date)).drop('Date',axis=1)\n",
    "    \n",
    "    # Standardwert für Zeitraum -> Maximum möglich\n",
    "    if Startdate==None:\n",
    "        Startdate=X.index.min()\n",
    "    if Enddate==None:\n",
    "        Enddate=X.index.max()\n",
    "    \n",
    "    #Filter Indexdaten auf gewünschten Index\n",
    "    r=r[r['ISIN_TRi']==IndexISIN]\n",
    "        \n",
    "    #Initialisierung leeres Portfolio\n",
    "    port=pd.DataFrame()\n",
    "    \n",
    "    # Trennung in Teilzeiträume    \n",
    "    dates=pd.date_range(Startdate,Enddate,freq='M')\n",
    "    \n",
    "    if len(dates)%m_rebal_freq!=0:\n",
    "        raise ValueError('Number of dates available must be multiple of Month rebalance')\n",
    "    \n",
    "    # Iteration über Zeiträume\n",
    "    for i in range(MonthRew-1,len(dates)-MonthRew,MonthRew):\n",
    "        \n",
    "        print('Starte Optimierung für ', dates[i])\n",
    "        \n",
    "        #Auswahl der Komponenten für kommenden Zeitraum \n",
    "        Components=Comp[dates[i+1].strftime('%Y%m')]\n",
    "        print('Components: ',Components.shape)\n",
    "\n",
    "        # Filter auf alle Komponentenzeitreihen des Vorzeitraumes und im neuen noch aktiv sind\n",
    "        Underlying=X[(X.index>=dates[i-MonthRew+1].replace(day=1)) & (X.index<=dates[i])]\n",
    "        Underlying=Underlying[Underlying['ISIN'].isin(list(Components['ISIN']))]\n",
    "        \n",
    "        #Bestimmung der Startgewichtung: entweder Startvektor oder aber die Gewichtung des Vorzeitraumes\n",
    "        if port.empty:\n",
    "            w=w0\n",
    "        else:\n",
    "            w=np.array(pd.merge(Underlying,port[port['Date']==port['Date'].max()],on='ISIN',how='left')\\\n",
    "                       .fillna(0).groupby('ISIN').mean()['Weight'])\n",
    "        \n",
    "        # Extraktion Return-Zeitreihen für Index und Underlyings\n",
    "        Underlying=Underlying.pivot(columns='ISIN',values='Daily Return').fillna(0)\n",
    "        print('Underlying: ',Underlying.shape)\n",
    "        Index=r[(r.index>=dates[i-MonthRew+1].replace(day=1)) & (r.index<=dates[i])]\n",
    "        Index=Index['Daily Return']\n",
    "        print('Index: ',Index.shape)\n",
    "        \n",
    "        # Wenn Steuervariable ret = Falsch, dann Umwandlung DailyReturns in fortlaufende Returns\n",
    "        Index_temp=pd.DataFrame(Index)\n",
    "        Underlying_temp=pd.DataFrame(Underlying)\n",
    "        if ret==False:\n",
    "            for j in range(len(Index)):\n",
    "                if j>0:\n",
    "                    Index[j]=(1+Index[j-1])*(1+Index[j])-1\n",
    "                    Underlying.iloc[j,:]=(1+Underlying.iloc[j-1,:])*(1+Underlying.iloc[j,:])-1\n",
    "        \n",
    "        result=SLAIT(X=Underlying,r=Index,u=u,measure=measure,eps=eps,M=M,maxiter=maxiter,lamb=lamb,w0=w,gamma=gamma,p=p,thres=thres)\n",
    "        result['Date']=dates[i]\n",
    "        result=result[result['Weight']>0]\n",
    "                \n",
    "        port=port.append(result,ignore_index=True)\n",
    "\n",
    "    return portfolio(port,X,r,Comp)#,Underlying,Index,Underlying_temp,Index_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einschränkung auf Komponenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in comp.keys():\n",
    "    print(comp[key].shape , key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_corp=dict(comp)\n",
    "for key in  comp.keys():\n",
    "    act_comp=comp_corp[key]\n",
    "    comp_corp[key]=act_comp[(act_comp['Level 2']=='Non-Financials') \\\n",
    "                      & (act_comp['Seniority Level 1']=='SEN') \\\n",
    "                      & (act_comp['Markit iBoxx Rating'].isin(['AAA','AA','A','BBB']))\n",
    "                      & (act_comp['Bid_Ask_Spread']<0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in comp_corp.keys():\n",
    "    print(comp_corp[key].shape , key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W1_Corp=MultiPeriod_SLAIT(underlyings_df,indices_df,comp_corp,Startdate='2020-01-01',Enddate='2022-03-31',maxiter=10000,eps=1e-7,m_rebal_freq=3,MonthRew=3,u=0.02,IndexISIN='DE000A0G84N4',lamb=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_Corp.weight.to_csv('results/Result_CorpW1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W2_Corp=MultiPeriod_SLAIT(underlyings_df,indices_df,comp_corp,Startdate='2020-01-01',Enddate='2022-05-31',maxiter=10000,eps=1e-7,m_rebal_freq=1,MonthRew=1,u=0.02,IndexISIN='DE000A0G84N4',lamb=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2_Corp.weight.to_csv('results/Result_CorpW2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3_Corp=MultiPeriod_SLAIT(underlyings_df,indices_df,comp_corp,Startdate='2020-01-01',Enddate='2022-05-31',maxiter=10000,eps=1e-7,m_rebal_freq=1,MonthRew=1,u=0.02,IndexISIN='DE000A0G84N4',lamb=1e-8)\n",
    "W3_Corp.weight.to_csv('results/Result_CorpW3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4_Corp=MultiPeriod_SLAIT(underlyings_df,indices_df,comp_corp,Startdate='2020-01-01',Enddate='2022-05-31',maxiter=10000,eps=1e-7,m_rebal_freq=1,MonthRew=3,u=0.02,IndexISIN='DE000A0G84N4',lamb=1e-8)\n",
    "W4_Corp.weight.to_csv('results/Result_CorpW4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W5_Corp=MultiPeriod_SLAIT(underlyings_df,indices_df,comp_corp,Startdate='2020-01-01',Enddate='2022-05-31',maxiter=10000,eps=1e-7,m_rebal_freq=1,MonthRew=3,u=0.01,IndexISIN='DE000A0G84N4',lamb=1e-7)\n",
    "W5_Corp.weight.to_csv('results/Result_CorpW5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
